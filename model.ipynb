{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Model For Line Properties\n",
    "\n",
    "Author: Jerry Chen\n",
    "\n",
    "General Overview:\n",
    "\n",
    "Input Parameters In Order\n",
    "* Flowrate - Q (uL/min)\n",
    "* Gantry Travel speed - V<sub>g</sub> (mm/min)\n",
    "* LDR - Q/V<sub>g</sub>\n",
    "* Print Height (mm)\n",
    "\n",
    "Output Parameters In Order\n",
    "* Average Width (μm)\n",
    "* Average Thickness (μm)\n",
    "\n",
    "Notes\n",
    "* Use categorized linear regression Plot Q,V, Line Width show LDR coefficent determination 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5394,  1.5381]) tensor([-1.8517, -1.8783])\n",
      "tensor([  80.9764, 1920.2285]) tensor([364.2700,  78.4050])\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "use_cuda = True\n",
    "device = 'cuda' if torch.cuda.is_available() and use_cuda else 'cpu'\n",
    "\n",
    "# Class to represent dataset\n",
    "\n",
    "\n",
    "class lineDataSet():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Loading the csv file from the folder path\n",
    "        # First row is data labels so delete\n",
    "        data1 = np.loadtxt('cleanlinedata.csv', delimiter=',',\n",
    "                           dtype=np.float32, skiprows=1)\n",
    "\n",
    "        # First 4 column are class parameters\n",
    "        # Last 2 are line properties\n",
    "        # Data in Each Column\n",
    "        # Q (uL/min), Vg (mm/min), LDR (μL/mm), Print Height (mm), Average Width (μm), Average Thickness (μm)\n",
    "\n",
    "        # Zero center and normalize input and output data\n",
    "        self.x = data1[:, [0, 1]]\n",
    "        self.input_mean = np.mean(self.x, axis=0)\n",
    "        self.input_std = np.std(self.x, axis=0)\n",
    "        self.x = torch.from_numpy((self.x-self.input_mean)/self.input_std)\n",
    "\n",
    "        self.y = data1[:, 4:]\n",
    "        self.output_mean = np.mean(self.y, axis=0)\n",
    "        self.output_std = np.std(self.y, axis=0)\n",
    "        self.y = torch.from_numpy((self.y-self.output_mean)/self.output_std)\n",
    "\n",
    "        self.n_samples = data1.shape[0]\n",
    "\n",
    "    # support indexing such that dataset[i] can\n",
    "    # be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "dataset = lineDataSet()\n",
    "\n",
    "first_data = dataset[0]\n",
    "inputs, outputs = first_data\n",
    "print(inputs, outputs)\n",
    "print(inputs*dataset.input_std+dataset.input_mean,\n",
    "      outputs*dataset.output_std+dataset.output_mean)\n",
    "\n",
    "# Expected Output\n",
    "# tensor([8.0976e+01, 1.9202e+03, 4.2170e-02, 2.0000e-01]) tensor([364.2700,  78.4050]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network model\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, channels=1):  # default grayscale\n",
    "        super().__init__()\n",
    "        # self.batch1 = nn.BatchNorm1d(2)\n",
    "        self.linear1 = nn.Linear(in_features=2, out_features=2)\n",
    "        self.linear2 = nn.Linear(in_features=2, out_features=2)\n",
    "        # self.linear3 = nn.Linear(in_features=20, out_features=20)\n",
    "        # self.linear4 = nn.Linear(in_features=2, out_features=2)\n",
    "        # self.linear5 = nn.Linear(in_features=2, out_features=2)\n",
    "        # self.linear6 = nn.Linear(in_features=2, out_features=2)\n",
    "        # self.linear7 = nn.Linear(in_features=2, out_features=2)\n",
    "        self.out = nn.Linear(in_features=2, out_features=2)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # t=self.batch1(t)\n",
    "        t = self.linear1(t)\n",
    "        t = torch.relu(t)\n",
    "        t = self.linear2(t)\n",
    "        t = torch.relu(t)\n",
    "        # t = self.linear3(t)\n",
    "        # t = torch.tanh(t)\n",
    "        # More layers generate more pronounced seperation\n",
    "        # t = self.linear2(t)\n",
    "        # t = F.tanh(t)\n",
    "        t = self.out(t)\n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "def train(step_size, batch_size=5, shuffle=False, num_epochs=5, plot_loss=False):\n",
    "    # Loading in data\n",
    "    dataset = lineDataSet()\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, test_size])\n",
    "    dsets = {'train': train_dataset, 'val': val_dataset}\n",
    "\n",
    "    # Data loading - batch_size and shuffle\n",
    "    dest_loader = {x: torch.utils.data.DataLoader(\n",
    "        dsets[x], batch_size=batch_size, shuffle=shuffle) for x in ['train', 'val']}\n",
    "\n",
    "    # Start network\n",
    "    network = Network()\n",
    "    if device == \"cuda\":\n",
    "        print(\"Using CUDA\")\n",
    "        network.cuda()\n",
    "\n",
    "    # Training\n",
    "    print('step_size=', step_size, 'batch_size=',\n",
    "          batch_size, 'shuffle=', shuffle, '\\n')\n",
    "\n",
    "    optimizer = optim.Adam(network.parameters(), lr=step_size)\n",
    "\n",
    "    best_epoch = 0\n",
    "    best_epoch_loss = np.inf\n",
    "\n",
    "    epoch_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_epoch_loss = 0\n",
    "        for mode in ['train', 'val']:\n",
    "            if mode == 'train':\n",
    "                network.train(True)    # Set model to training mode\n",
    "            else:\n",
    "                network.train(False)    # Set model to Evaluation mode\n",
    "                network.eval()\n",
    "\n",
    "            for input_val, out_val in dest_loader[mode]:\n",
    "                if device == \"cuda\":\n",
    "                    input_val = input_val.cuda()\n",
    "                    out_val = out_val.cuda()\n",
    "\n",
    "                optimizer.zero_grad()    # Zero the gradients of the network weights prior to backprop\n",
    "                # Forward pass through the network - Shape batch x output\n",
    "                preds = network(input_val)\n",
    "\n",
    "                # Compute the minibatch loss with mean squared error\n",
    "                minibatch_loss = F.mse_loss(preds, out_val)\n",
    "\n",
    "                if mode == 'val':\n",
    "                    error = torch.sqrt(torch.sum((preds-out_val)**2, dim=-1))\n",
    "                    real_val = torch.sqrt(torch.sum(out_val**2, dim=-1))\n",
    "\n",
    "                    # Add minibatch loss to the epoch loss\n",
    "                    avg_epoch_loss += torch.sum(error/real_val)\n",
    "                    # raise Exception(\"Finished code\")\n",
    "\n",
    "                if mode == 'train':  # only backprop through training loss and not validation loss\n",
    "                    minibatch_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            if mode == 'val':\n",
    "                avg_epoch_loss /= len(val_dataset)\n",
    "                epoch_losses.append(avg_epoch_loss.cpu().detach().numpy())\n",
    "\n",
    "                print(f\"epoch:{epoch}\\t avg_val_MSE_error:{avg_epoch_loss}\")\n",
    "                print(\"Prediction: {:.2f} {:.2f} Actual: {:.2f} {:.2f}\".format(\n",
    "                    preds[0][0].item(), preds[0][1].item(),\n",
    "                    out_val[0][0].item(), out_val[0][1].item()))\n",
    "\n",
    "                if avg_epoch_loss < best_epoch_loss:\n",
    "                    best_epoch_loss = avg_epoch_loss\n",
    "                    best_epoch = epoch\n",
    "                    torch.save(network.state_dict(), f'best_model.pth')\n",
    "\n",
    "    print(f\"Best epoch {best_epoch}\")\n",
    "\n",
    "    if plot_loss:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot([i for i in range(num_epochs)], epoch_losses)\n",
    "        ax.set(xlabel='Epoch', ylabel='Percent Loss',\n",
    "               title='Loss Per Epoch')\n",
    "        ax.grid()\n",
    "        plt.show()\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "lr_list = [0.1, 0.01, 0.001]\n",
    "batch_size_list = [10, 100, 1000]\n",
    "shuffle_list = [True, False]\n",
    "\n",
    "# hyperparameter grid search\n",
    "# for param in product(lr_list, batch_size_list, shuffle_list):\n",
    "\n",
    "\n",
    "best_network = train(0.01, shuffle=True, num_epochs=100, plot_loss=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lineDataSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m lineDataSet()\n\u001b[1;32m      3\u001b[0m best_network \u001b[39m=\u001b[39m Network()\n\u001b[1;32m      4\u001b[0m best_network\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mbest_model.pth\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lineDataSet' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = lineDataSet()\n",
    "\n",
    "best_network = Network()\n",
    "best_network.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "'''\n",
    "print(best_network)\n",
    "\n",
    "for m in best_network.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        print(m.state_dict()['weight'])\n",
    "        print(m.state_dict()['bias'])\n",
    "'''\n",
    "\n",
    "# Turn of gradiant\n",
    "with torch.no_grad():\n",
    "    best_network.eval()\n",
    "\n",
    "    network = best_network.cpu()\n",
    "\n",
    "    pred = network(dataset[:][0])\n",
    "\n",
    "    # X = [Q (uL/min), Vg (mm/min)]\n",
    "    # Y =  [Average Width (μm), Average Thickness (μm)]\n",
    "    Q = dataset[:][0][:, 0]*dataset.input_std[0]+dataset.input_mean[0]\n",
    "    Q = Q.numpy()\n",
    "    flow_rate_sort_idx = np.argsort(Q)\n",
    "    Q = Q[flow_rate_sort_idx]\n",
    "\n",
    "    Vg = dataset[:][0][:, 1]*dataset.input_std[1]+dataset.input_mean[1]\n",
    "    Vg = Vg.numpy()\n",
    "    Vg = Vg[flow_rate_sort_idx]\n",
    "\n",
    "    avg_width = dataset[:][1][:, 0] * \\\n",
    "        dataset.output_std[0]+dataset.output_mean[0]\n",
    "    avg_width = avg_width.numpy()\n",
    "    avg_width = avg_width[flow_rate_sort_idx]\n",
    "\n",
    "    avg_width_pred = pred[:, 0] * \\\n",
    "        dataset.output_std[0] + dataset.output_mean[0]\n",
    "    avg_width_pred = avg_width_pred.numpy()\n",
    "    avg_width_pred = avg_width_pred[flow_rate_sort_idx]\n",
    "\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax=plt.axes()\n",
    "    ax.plot(Q/Vg, avg_width_pred)\n",
    "    #ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "    #ax.scatter(Q, Vg, avg_width,  edgecolor='royalblue')\n",
    "    #ax.scatter(Q, Vg, avg_width_pred,  edgecolor='royalblue')\n",
    "    #ax.plot_trisurf(Q, Vg, avg_width,  edgecolor='royalblue')\n",
    "    #ax.plot_trisurf(Q, Vg, avg_width_pred,  edgecolor='r')\n",
    "    plt.show()\n",
    "\n",
    "    '''\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "    axs[0].plot(Q, avg_width, 'r')\n",
    "    #axs[0].plot(Q, avg_width_pred, 'b')\n",
    "    #axs[0].set_xlabel(\"Flow Rate\")\n",
    "    #axs[0].set_ylabel(\"Gantry Speed\")\n",
    "    #axs[0].set_zlabel(\"Print Width\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # axs[1].plot(dataset[:][0][:, 0]+dataset.input_mean[2],\n",
    "    #            dataset[:][1][:, 1], 'r')\n",
    "    # axs[1].plot(dataset[:]# Q (uL/min), Vg (mm/min),LDR (μL/mm), Print Height (mm), Average Width (μm), Average Thickness (μm)[0][:, 0]+dataset.input_mean[2], pred[:, 1], 'b')\n",
    "    # axs[1].set_xlabel(\"LDR\")\n",
    "    # axs[1].set_ylabel(\"Average Height\")\n",
    "    # axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "  \n",
    "    # for param in network.parameters():\n",
    "    #    print(param)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
